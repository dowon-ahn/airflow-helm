---
# Source: airflow/templates/configmaps/configmap.yaml
################################
## Airflow ConfigMap
#################################
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  namespace: "airflow-helm-project"
  labels:
    tier: airflow
    component: config
    release: airflow
    chart: "airflow-1.12.0"
    heritage: Helm
data:
  # These are system-specified config overrides.
  airflow.cfg: |-
    [celery]
    flower_url_prefix = 
    worker_concurrency = 16
    
    [celery_kubernetes_executor]
    kubernetes_queue = kubernetes
    
    [core]
    colored_console_log = False
    dags_folder = /opt/airflow/dags
    executor = KubernetesExecutor
    load_examples = False
    remote_logging = False
    
    [elasticsearch]
    json_format = True
    log_id_template = {dag_id}_{task_id}_{execution_date}_{try_number}
    
    [elasticsearch_configs]
    max_retries = 3
    retry_timeout = True
    timeout = 30
    
    [kerberos]
    ccache = /var/kerberos-ccache/cache
    keytab = /etc/airflow.keytab
    principal = airflow@FOO.COM
    reinit_frequency = 3600
    
    [kubernetes]
    airflow_configmap = airflow-config
    airflow_local_settings_configmap = airflow-config
    multi_namespace_mode = False
    namespace = airflow
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 2.8.1
    
    [kubernetes_executor]
    multi_namespace_mode = False
    namespace = airflow
    pod_template_file = /opt/airflow/pod_templates/pod_template_file.yaml
    worker_container_repository = apache/airflow
    worker_container_tag = 2.8.1
    
    [logging]
    colored_console_log = False
    remote_logging = False
            
    [scheduler]
    run_duration = 41460
    standalone_dag_processor = False
    
    [triggerer]
    default_capacity = 1000
    
    [webserver]
    enable_proxy_fix = True
    rbac = True

  airflow_local_settings.py: |-
    
    from airflow.www.utils import UIAlert
    
    DASHBOARD_UIALERTS = [
      UIAlert(
        'Usage of a dynamic webserver secret key detected. We recommend a static webserver secret key instead.'
        ' See the <a href='
        '"https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key">'
        'Helm Chart Production Guide</a> for more details.',
        category="warning",
        roles=["Admin"],
        html=True,
      )
    ]
  pod_template_file.yaml: |-
    
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      name: placeholder-name
      namespace: "airflow-helm-project"
      labels:
        tier: airflow
        component: worker
        release: airflow
    spec:
      containers:
        - envFrom:      
            []
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: LocalExecutor      
            # Hard Coded Airflow Envs
            - name: AIRFLOW__CORE__FERNET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-fernet-key
                  key: fernet-key
            - name: AIRFLOW_HOME
              value: /opt/airflow
            # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
            - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW_CONN_AIRFLOW_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-metadata
                  key: connection
            - name: AIRFLOW__WEBSERVER__SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: airflow-webserver-secret-key
                  key: webserver-secret-key      
            # Dynamically created environment variables
            # Dynamically created secret envs
            
            # Extra env      
          image: apache/airflow:2.8.1
          imagePullPolicy: IfNotPresent
          securityContext: 
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          name: base
          resources:
            {}
          volumeMounts:
            - mountPath: "/opt/airflow/logs"
              name: nfs-logs-volume
              readOnly: false  
            - name: nfs-dags-volume
              mountPath: "/opt/airflow/dags"
              readOnly: false   
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
      restartPolicy: Never
      securityContext: 
        runAsUser: 50000
        fsGroup: 0
      nodeSelector:
        {}
      affinity:
        {}
      terminationGracePeriodSeconds: 600
      tolerations:
        []
      topologySpreadConstraints:
        []
      serviceAccountName: airflow-worker
      volumes:
        - name: nfs-logs-volume
          nfs:
            server: 192.168.190.135   # NFS 서버의 IP 주소
            path: /home/nfs/logs # NFS 공유 디렉토리의 경로
        - name: config
          configMap:
            name: airflow-config
        - name: nfs-dags-volume
          nfs:
            server: 192.168.190.135   # NFS 서버의 IP 주소
            path: /home/nfs/dags/ # NFS 공유 디렉토리의 경로